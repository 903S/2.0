{
  "Episode/Reward": {
    "steps": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "values": [
      -2.0,
      -2.0,
      -1.9288123846054077,
      -2.0,
      -2.0,
      -2.0,
      -3.0154576301574707,
      -2.0,
      -1.7528722286224365,
      0.6851802468299866,
      -2.9594109058380127,
      -2.94347882270813,
      -3.0,
      -2.0085527896881104,
      -1.8934307098388672,
      0.6371431946754456,
      -2.0,
      -2.9490225315093994,
      -2.0,
      -3.0
    ],
    "count": 20
  },
  "Episode/Length": {
    "steps": [
      0,
      1,
      2,
      3,
      4,
      5,
      6,
      7,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "values": [
      2.0,
      2.0,
      4.0,
      1.0,
      2.0,
      1.0,
      6.0,
      1.0,
      7.0,
      5.0,
      8.0,
      4.0,
      2.0,
      3.0,
      6.0,
      6.0,
      2.0,
      6.0,
      2.0,
      2.0
    ],
    "count": 20
  },
  "Episode/step": {
    "steps": [
      0,
      1,
      2,
      4,
      6,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "values": [
      1.0,
      1.0,
      3.0,
      1.0,
      5.0,
      6.0,
      5.0,
      7.0,
      3.0,
      1.0,
      2.0,
      5.0,
      6.0,
      1.0,
      5.0,
      1.0,
      1.0
    ],
    "count": 17
  },
  "Episode/reward": {
    "steps": [
      0,
      1,
      2,
      4,
      6,
      8,
      9,
      10,
      11,
      12,
      13,
      14,
      15,
      16,
      17,
      18,
      19
    ],
    "values": [
      0.0,
      0.0,
      0.0008160058641806245,
      0.0,
      -0.00949792843312025,
      -0.00682207802310586,
      0.8401849269866943,
      0.0667356625199318,
      -0.011851465329527855,
      0.0,
      -0.008552814833819866,
      -0.010195364244282246,
      0.7441661357879639,
      0.0,
      0.07304471731185913,
      0.0,
      0.0
    ],
    "count": 17
  },
  "Episode/early_termination": {
    "steps": [
      9,
      15
    ],
    "values": [
      1.0,
      1.0
    ],
    "count": 2
  },
  "Episode/plateau_confidence": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.9960732460021973,
      0.935744047164917
    ],
    "count": 2
  },
  "Episode/balance_reward": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.2821713089942932,
      0.07234903424978256
    ],
    "count": 2
  },
  "Episode/decoupling_reward": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.7295419573783875,
      0.8276001811027527
    ],
    "count": 2
  },
  "Episode/power_reward": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.16705305874347687,
      0.11727048456668854
    ],
    "count": 2
  },
  "Episode/quality_reward": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.43809592723846436,
      0.3834337890148163
    ],
    "count": 2
  },
  "Episode/threshold_bonus": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.0,
      0.0
    ],
    "count": 2
  },
  "Episode/termination_discount": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.5,
      0.5
    ],
    "count": 2
  },
  "Episode/final_reward": {
    "steps": [
      9,
      15
    ],
    "values": [
      0.21904796361923218,
      0.19171689450740814
    ],
    "count": 2
  },
  "Training/ActorLoss": {
    "steps": [
      10
    ],
    "values": [
      0.2358640879392624
    ],
    "count": 1
  },
  "Training/CriticLoss": {
    "steps": [
      10
    ],
    "values": [
      4.669838905334473
    ],
    "count": 1
  },
  "Training/Entropy": {
    "steps": [
      10
    ],
    "values": [
      2.6197316646575928
    ],
    "count": 1
  }
}